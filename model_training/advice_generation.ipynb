{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "522203571dc9421381d8ca53600af4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b34960acd44f4788b707b91457b035e1",
              "IPY_MODEL_75362412bf1441ada8d5e888cec0cf0a",
              "IPY_MODEL_8e0d031586424948bb1d16a8f67d8f84"
            ],
            "layout": "IPY_MODEL_39e60a21d2384b9486d95b1079a99a4c"
          }
        },
        "b34960acd44f4788b707b91457b035e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ddb3976e494b18978ca3c72efce271",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d5843455d9fb452f9dc042b716e50e13",
            "value": "Map:‚Äá100%"
          }
        },
        "75362412bf1441ada8d5e888cec0cf0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85e82451fe96421e9914fe89ce185c26",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a707bd9da7f44faa8a07ab067d23019",
            "value": 1208
          }
        },
        "8e0d031586424948bb1d16a8f67d8f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf6305a25a2b4b98b4dfc2847ab08b5e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2c81d1f044b244b790331c710547a651",
            "value": "‚Äá1208/1208‚Äá[00:01&lt;00:00,‚Äá656.00‚Äáexamples/s]"
          }
        },
        "39e60a21d2384b9486d95b1079a99a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81ddb3976e494b18978ca3c72efce271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5843455d9fb452f9dc042b716e50e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85e82451fe96421e9914fe89ce185c26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a707bd9da7f44faa8a07ab067d23019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf6305a25a2b4b98b4dfc2847ab08b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c81d1f044b244b790331c710547a651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f9236cabdb64d0bb8fad6d4e5f6cdcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09a60fdd1d0c45a688845fda238dec8f",
              "IPY_MODEL_5cef791bf4ef48868407cc527b41e800",
              "IPY_MODEL_83292900096d49c9acbb3c647e1d5e99"
            ],
            "layout": "IPY_MODEL_57a950d52b984acb9ac4c7927b7f416c"
          }
        },
        "09a60fdd1d0c45a688845fda238dec8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068302b192994da099ac593425bdc3fb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_537faa8719b4462da5a8409813c7f9ac",
            "value": "Map:‚Äá100%"
          }
        },
        "5cef791bf4ef48868407cc527b41e800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d67408898464731b4ca42154dff3404",
            "max": 259,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b233808ae84945c0bfb1f96f0ea5c4a7",
            "value": 259
          }
        },
        "83292900096d49c9acbb3c647e1d5e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cae483fa3b0342bc9008b302ef661e19",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f45ecb4c493c48eb984fc1c85aaf96a5",
            "value": "‚Äá259/259‚Äá[00:00&lt;00:00,‚Äá532.75‚Äáexamples/s]"
          }
        },
        "57a950d52b984acb9ac4c7927b7f416c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "068302b192994da099ac593425bdc3fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537faa8719b4462da5a8409813c7f9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d67408898464731b4ca42154dff3404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b233808ae84945c0bfb1f96f0ea5c4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cae483fa3b0342bc9008b302ef661e19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45ecb4c493c48eb984fc1c85aaf96a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2WBroqXJl5U",
        "outputId": "a718b875-6071-4807-9cdc-d9e71250f027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def prepare_datasets(train_data, val_data, test_data):\n",
        "    \"\"\"\n",
        "    Prepare datasets for training\n",
        "\n",
        "    Args:\n",
        "        train_data (pd.DataFrame): Training data\n",
        "        val_data (pd.DataFrame): Validation data\n",
        "        test_data (pd.DataFrame): Test data\n",
        "\n",
        "    Returns:\n",
        "        Tuple of prepared datasets\n",
        "    \"\"\"\n",
        "    def combine_input(row):\n",
        "        return (\n",
        "            f\"Emotion: {row['emotion']} | \"\n",
        "            f\"Context: {row['context']} | \"\n",
        "            f\"Trait: {row['trait']} | \"\n",
        "            f\"Topic: {row['topic']} | \"\n",
        "            f\"Advice: {row['advice']}\"\n",
        "        )\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_data['full_input'] = train_data.apply(combine_input, axis=1)\n",
        "    val_data['full_input'] = val_data.apply(combine_input, axis=1)\n",
        "    test_data['full_input'] = test_data.apply(combine_input, axis=1)\n",
        "\n",
        "    # Convert to Hugging Face datasets\n",
        "    train_dataset = Dataset.from_pandas(train_data[['full_input']])\n",
        "    val_dataset = Dataset.from_pandas(val_data[['full_input']])\n",
        "    test_dataset = Dataset.from_pandas(test_data[['full_input']])\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "def tokenize_function(tokenizer, examples):\n",
        "    \"\"\"\n",
        "    Tokenize input texts\n",
        "\n",
        "    Args:\n",
        "        tokenizer (GPT2Tokenizer): Tokenizer to use\n",
        "        examples (dict): Dictionary of input texts\n",
        "\n",
        "    Returns:\n",
        "        Tokenized inputs\n",
        "    \"\"\"\n",
        "    return tokenizer(\n",
        "        examples['full_input'],\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "def train_advice_model(train_dataset, val_dataset, model_name='gpt2', learning_rate=5e-5):\n",
        "    \"\"\"\n",
        "    Train the advice generation model\n",
        "\n",
        "    Args:\n",
        "        train_dataset (Dataset): Training dataset\n",
        "        val_dataset (Dataset): Validation dataset\n",
        "        model_name (str): Base model to use\n",
        "        learning_rate (float): Learning rate for training\n",
        "\n",
        "    Returns:\n",
        "        Tuple of trained model and tokenizer\n",
        "    \"\"\"\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "    # Configure tokenizer\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = 'left'\n",
        "\n",
        "    # Move model to device\n",
        "    model.to(device)\n",
        "\n",
        "    # Tokenize datasets\n",
        "    tokenize_func = lambda examples: tokenize_function(tokenizer, examples)\n",
        "    tokenized_train = train_dataset.map(\n",
        "        tokenize_func,\n",
        "        batched=True,\n",
        "        remove_columns=['full_input']\n",
        "    )\n",
        "    tokenized_val = val_dataset.map(\n",
        "        tokenize_func,\n",
        "        batched=True,\n",
        "        remove_columns=['full_input']\n",
        "    )\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer,\n",
        "        mlm=False\n",
        "    )\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./advice_model',\n",
        "        evaluation_strategy='epoch',\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        num_train_epochs=5,\n",
        "        weight_decay=0.01,\n",
        "        push_to_hub=False,\n",
        "        logging_dir='./logs',\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_val,\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save model\n",
        "    model.save_pretrained('./advice_model')\n",
        "    tokenizer.save_pretrained('./advice_model')\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "def generate_advice(model, tokenizer, emotion, context, trait, topic, max_length=50):\n",
        "    \"\"\"\n",
        "    Generate concise and accurate advice based on input parameters.\n",
        "\n",
        "    Args:\n",
        "        model (GPT2LMHeadModel): Trained model\n",
        "        tokenizer (GPT2Tokenizer): Tokenizer\n",
        "        emotion (str): Emotion of the scenario\n",
        "        context (str): Context of the situation\n",
        "        trait (str): Personality trait\n",
        "        topic (str): Topic of advice\n",
        "        max_length (int): Maximum length of generated advice\n",
        "\n",
        "    Returns:\n",
        "        str: Generated advice\n",
        "    \"\"\"\n",
        "    # Construct input text\n",
        "    input_text = (\n",
        "        f\"Emotion: {emotion} | \"\n",
        "        f\"Context: {context} | \"\n",
        "        f\"Trait: {trait} | \"\n",
        "        f\"Topic: {topic} | \"\n",
        "        f\"Advice: \"\n",
        "    )\n",
        "\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    # Generate advice with adjusted parameters for accuracy and brevity\n",
        "    outputs = model.generate(\n",
        "        inputs.input_ids,\n",
        "        max_length=100,  # Increase the upper bound\n",
        "        min_length=50,   # Ensure longer, meaningful responses\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=3,  # Prevent repetitive phrases\n",
        "        top_k=50,  # Consider a slightly broader range of options for creativity\n",
        "        top_p=0.95,  # Increase flexibility while focusing on high-probability tokens\n",
        "        temperature=0.7,  # Add slight randomness for natural and nuanced advice\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "\n",
        "    # Decode and extract advice\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract advice part (after \"Advice: \")\n",
        "    advice_start = generated_text.find(\"Advice: \") + len(\"Advice: \")\n",
        "    advice = generated_text[advice_start:].strip()\n",
        "\n",
        "    return advice\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to demonstrate model training and inference\n",
        "    \"\"\"\n",
        "    # Load your datasets (replace with your actual data loading)\n",
        "    try:\n",
        "        train_data = pd.read_csv(\"/content/sample_data/train.csv\")\n",
        "        val_data = pd.read_csv(\"/content/sample_data/val.csv\")\n",
        "        test_data = pd.read_csv(\"/content/sample_data/test.csv\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: CSV files not found. Please ensure train.csv, val.csv, and test.csv exist.\")\n",
        "        return\n",
        "\n",
        "    # Prepare datasets\n",
        "    train_dataset, val_dataset, _ = prepare_datasets(train_data, val_data, test_data)\n",
        "\n",
        "    # Train model\n",
        "    print(\"Training advice generation model...\")\n",
        "    model, tokenizer = train_advice_model(train_dataset, val_dataset)\n",
        "\n",
        "    # Example inference\n",
        "    print(\"\\nGenerating sample advice...\")\n",
        "    sample_advice = generate_advice(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        emotion=\"sadness\",\n",
        "        context=\"I failed my test and feel like I'm disappointing everyone\",\n",
        "        trait=\"INFJ\",\n",
        "        topic=\"academics\"\n",
        "    )\n",
        "    print(\"Generated Advice:\", sample_advice)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658,
          "referenced_widgets": [
            "522203571dc9421381d8ca53600af4e9",
            "b34960acd44f4788b707b91457b035e1",
            "75362412bf1441ada8d5e888cec0cf0a",
            "8e0d031586424948bb1d16a8f67d8f84",
            "39e60a21d2384b9486d95b1079a99a4c",
            "81ddb3976e494b18978ca3c72efce271",
            "d5843455d9fb452f9dc042b716e50e13",
            "85e82451fe96421e9914fe89ce185c26",
            "9a707bd9da7f44faa8a07ab067d23019",
            "cf6305a25a2b4b98b4dfc2847ab08b5e",
            "2c81d1f044b244b790331c710547a651",
            "7f9236cabdb64d0bb8fad6d4e5f6cdcd",
            "09a60fdd1d0c45a688845fda238dec8f",
            "5cef791bf4ef48868407cc527b41e800",
            "83292900096d49c9acbb3c647e1d5e99",
            "57a950d52b984acb9ac4c7927b7f416c",
            "068302b192994da099ac593425bdc3fb",
            "537faa8719b4462da5a8409813c7f9ac",
            "5d67408898464731b4ca42154dff3404",
            "b233808ae84945c0bfb1f96f0ea5c4a7",
            "cae483fa3b0342bc9008b302ef661e19",
            "f45ecb4c493c48eb984fc1c85aaf96a5"
          ]
        },
        "id": "iSF3klGWL0FD",
        "outputId": "72eef899-bac7-4d12-da96-d7bc960e009c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training advice generation model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1208 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "522203571dc9421381d8ca53600af4e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/259 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f9236cabdb64d0bb8fad6d4e5f6cdcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241220_123605-jlwfow1o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/stefaniesamaha15-american-university-of-beirut/huggingface/runs/jlwfow1o' target=\"_blank\">./advice_model</a></strong> to <a href='https://wandb.ai/stefaniesamaha15-american-university-of-beirut/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/stefaniesamaha15-american-university-of-beirut/huggingface' target=\"_blank\">https://wandb.ai/stefaniesamaha15-american-university-of-beirut/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/stefaniesamaha15-american-university-of-beirut/huggingface/runs/jlwfow1o' target=\"_blank\">https://wandb.ai/stefaniesamaha15-american-university-of-beirut/huggingface/runs/jlwfow1o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1510' max='1510' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1510/1510 11:13, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.861086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.417000</td>\n",
              "      <td>1.732322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.417000</td>\n",
              "      <td>1.698344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.525000</td>\n",
              "      <td>1.686752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.317400</td>\n",
              "      <td>1.697709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating sample advice...\n",
            "Generated Advice: ____________Failed tests hurt, but you‚Äôre still learning. Focus on your goals and approach the test with curiosity. Remember, every effort counts, and you‚Äòre capable of growing. Practice, practice, and trust that your hard work will pay off‚Äîyou‚Äôve got this.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load the trained model and tokenizer from the saved directory\n",
        "model = GPT2LMHeadModel.from_pretrained('./advice_model')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('./advice_model')\n",
        "\n",
        "# Move the model to the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define the interactive advice generator function\n",
        "def interactive_advice_generator(model, tokenizer):\n",
        "    \"\"\"\n",
        "    Interactive function to generate advice based on user inputs.\n",
        "\n",
        "    Args:\n",
        "        model: The trained GPT-2 model.\n",
        "        tokenizer: The tokenizer for the model.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(\"Interactive Advice Generator\")\n",
        "    print(\"=============================\")\n",
        "\n",
        "    while True:\n",
        "        # Collect user inputs\n",
        "        emotion = input(\"Enter the emotion (e.g., sadness, happiness): \").strip()\n",
        "        context = input(\"Enter the context of the situation: \").strip()\n",
        "        trait = input(\"Enter the personality trait (e.g., INFJ, ENFP): \").strip()\n",
        "        topic = input(\"Enter the topic for advice (e.g., academics, relationships): \").strip()\n",
        "\n",
        "        # Generate advice\n",
        "        advice = generate_advice(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            emotion=emotion,\n",
        "            context=context,\n",
        "            trait=trait,\n",
        "            topic=topic,\n",
        "            max_length=100  # Adjust as needed\n",
        "        )\n",
        "\n",
        "        # Display the generated advice\n",
        "        print(\"\\nGenerated Advice:\")\n",
        "        print(advice)\n",
        "\n",
        "        # Ask if the user wants to continue\n",
        "        continue_response = input(\"\\nDo you want to generate another advice? (yes/no): \").strip().lower()\n",
        "        if continue_response != 'yes':\n",
        "            print(\"\\nThank you for using the Advice Generator!\")\n",
        "            break\n",
        "\n",
        "# Run the interactive generator\n",
        "interactive_advice_generator(model, tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJDsW-QIPAJp",
        "outputId": "e4c55174-b139-41b9-87e5-4f5a06c42685"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interactive Advice Generator\n",
            "=============================\n",
            "Enter the emotion (e.g., sadness, happiness): sadness\n",
            "Enter the context of the situation: My TikTok flopped, and now I‚Äôm doubting my content.\n",
            "Enter the personality trait (e.g., INFJ, ENFP): ENFJ\n",
            "Enter the topic for advice (e.g., academics, relationships): social media\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Advice:\n",
            "√Ç Use a different social media channel to self-discovery and celebrate your growth. Embrace your inherent creativity and resilience. You‚Äôre on the right track‚Äîyou‚Äôve got this! Start small, but remember, no one expects perfection.‚Äôs perfection is just a small\n",
            "\n",
            "Do you want to generate another advice? (yes/no): no\n",
            "\n",
            "Thank you for using the Advice Generator!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "# ======= 1. Save the Retrained Model =======\n",
        "# Define the directory to save the model\n",
        "output_model_path = \"/content/retrained_sentencebert_model\"\n",
        "\n",
        "# Save the model\n",
        "model.save(output_model_path)\n",
        "print(f\"Model saved at: {output_model_path}\")\n",
        "\n",
        "# ======= 2. Load the Retrained Model =======\n",
        "# Load the retrained SentenceBERT model\n",
        "retrained_model = SentenceTransformer(output_model_path)\n",
        "print(\"Retrained model loaded successfully!\")\n",
        "\n",
        "# ======= 3. Input GPT-2 Outputs and Reference Sentences =======\n",
        "# GPT-2 outputs (Generated sentences)\n",
        "gpt2_outputs = [\n",
        "    \"Embrace this step toward greater fulfillment and growth. Cherish the moment of your journey and remember that love is a sanctuary of unconditional love.\",\n",
        "    \"It's actually all about the possibilities. Focus on what'll come your way, and remember - you're capable of amazing things. Your journey is not a destination.\"\n",
        "    \"This concert is the perfect way to reconnect with loved ones. Music is a way to celebrate your connnection and express yourself. Keep the energy alive!\"\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "# Reference sentences to compare against\n",
        "reference_sentences = [\n",
        "    \"Regular exercise is important for maintaining good health.\",\n",
        "    \"Include fruits and vegetables in your daily meals to stay healthy.\"\n",
        "]\n",
        "\n",
        "# ======= 4. Encode the Sentences =======\n",
        "# Encode GPT-2 outputs and reference sentences\n",
        "gpt2_embeddings = retrained_model.encode(gpt2_outputs, convert_to_tensor=True)\n",
        "reference_embeddings = retrained_model.encode(reference_sentences, convert_to_tensor=True)\n",
        "\n",
        "# ======= 5. Compute Semantic Similarity =======\n",
        "# Compute cosine similarity for each pair\n",
        "similarities = cosine_similarity(gpt2_embeddings, reference_embeddings)\n",
        "\n",
        "# Print individual similarity scores\n",
        "print(\"\\nSimilarity Scores for GPT-2 Outputs vs Reference Sentences:\")\n",
        "for i, sim in enumerate(similarities):\n",
        "    print(f\"Generated Sentence {i+1} vs Reference: {sim.item():.4f}\")\n",
        "\n",
        "# Compute the average similarity across all pairs\n",
        "average_similarity = similarities.mean().item()\n",
        "print(f\"\\nAverage Semantic Similarity: {average_similarity:.4f}\")\n",
        "\n",
        "# # ======= 6. Save the Model for Future Use =======\n",
        "# # Save the model to Google Drive (Optional)\n",
        "# drive_model_path = \"/content/drive/My Drive/retrained_sentencebert_model\"\n",
        "# model.save(drive_model_path)\n",
        "# print(f\"Model saved to Google Drive at: {drive_model_path}\")\n"
      ],
      "metadata": {
        "id": "g_SrLj_jHJDm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}